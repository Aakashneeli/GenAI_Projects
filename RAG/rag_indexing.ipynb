{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv , find_dotenv\n",
    "import os\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator \n",
    "from langchain.embeddings import OpenAIEmbeddings # importing embedding models \n",
    "from langchain import OpenAI\n",
    "import openai\n",
    "from langchain_community.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the PDF\n",
    "loader  = PyPDFLoader(\"C:\\\\Users\\\\Admin\\\\Documents\\\\gen_ai_training\\\\pdfs\\\\rag.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "#splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100, add_start_index=True)\n",
    "chunks = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks indexed: 276\n"
     ]
    }
   ],
   "source": [
    "# Embedding \n",
    "#Using FAISS vector DB\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(chunks, embedding=embeddings)  # Pass embeddings as parameter\n",
    "print(f\"Total chunks indexed: {db.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#Integrating with openAI to get better query results\n",
    "llm = OpenAI(temperature=0.2)\n",
    "\n",
    "def generate_response(query, llm, db, top_k=4):\n",
    "    # Perform similarity search to retrieve relevant text chunks\n",
    "    chunks = db.similarity_search(query, k=top_k)\n",
    "    \n",
    "    # Combine the content of the top-k chunks into a single text string\n",
    "    combined_text = \"\\n\".join([chunk.page_content for chunk in chunks])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Generate response using OpenAI API\n",
    "    response =openai.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=f\"Based on the following content, answer the query and if its not in the content then say i dont know : {query}\\n\\nContent:\\n{combined_text}\\n\\nAnswer:\",\n",
    "        max_tokens = 150\n",
    "    )\n",
    "     # Extract the response text\n",
    "    response_text = response.choices[0].text.strip()\n",
    "    \n",
    "    # Return response along with metadata\n",
    "    return response_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to 'explain thouroughly the 3 types of RAG?': The three types of RAG are Naive RAG, Advanced RAG, and Modular RAG. Naive RAG mainly consists of three parts: indexing, retrieval, and generation. Advanced RAG proposes multiple optimization strategies and has a similar process to Naive RAG. Modular RAG showcases greater flexibility overall and responds to the specific shortcomings of Naive RAG. RAG's technical integration with other AI methodologies, such as fine-tuning and reinforcement learning, has further expanded its capabilities. Despite the progress in RAG technology, there are still opportunities for research to improve its robustness and ability to handle extended contexts. RAG's application scope is also expanding into multimodal domains.\n"
     ]
    }
   ],
   "source": [
    "query = \"explain thoroughly the 3 types of RAG?\"\n",
    "response = generate_response(query, embeddings, db)\n",
    "print(f\"Response to '{query}': {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
